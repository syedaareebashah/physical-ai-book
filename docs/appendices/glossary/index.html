<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-appendices/glossary" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Appendix E: Glossary | Physical AI &amp; Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://syedaareebashah.github.io/physical-ai-book/img/physical-ai-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://syedaareebashah.github.io/physical-ai-book/img/physical-ai-social-card.jpg"><meta data-rh="true" property="og:url" content="https://syedaareebashah.github.io/physical-ai-book/docs/appendices/glossary"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Appendix E: Glossary | Physical AI &amp; Humanoid Robotics"><meta data-rh="true" name="description" content="A"><meta data-rh="true" property="og:description" content="A"><link data-rh="true" rel="icon" href="/physical-ai-book/img/icono.svg"><link data-rh="true" rel="canonical" href="https://syedaareebashah.github.io/physical-ai-book/docs/appendices/glossary"><link data-rh="true" rel="alternate" href="https://syedaareebashah.github.io/physical-ai-book/docs/appendices/glossary" hreflang="en"><link data-rh="true" rel="alternate" href="https://syedaareebashah.github.io/physical-ai-book/docs/appendices/glossary" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Appendix E: Glossary","item":"https://syedaareebashah.github.io/physical-ai-book/docs/appendices/glossary"}]}</script><link rel="alternate" type="application/rss+xml" href="/physical-ai-book/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/physical-ai-book/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="Physical AI &amp; Humanoid Robotics" href="/physical-ai-book/opensearch.xml">
<link rel="stylesheet" href="/css/editorial-theme.css" crossorigin="undefined">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;800&amp;family=Space+Grotesk:wght@400;500;600;700&amp;display=swap" crossorigin="undefined"><link rel="stylesheet" href="/physical-ai-book/assets/css/styles.9907649b.css">
<script src="/physical-ai-book/assets/js/runtime~main.33dbc0e9.js" defer="defer"></script>
<script src="/physical-ai-book/assets/js/main.20838fba.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/physical-ai-book/img/robot-logo.png"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/physical-ai-book/"><div class="navbar__logo"><img src="/physical-ai-book/img/robot-logo.png" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/physical-ai-book/img/robot-logo.png" alt="Physical AI Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI &amp; Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/physical-ai-book/docs/intro">Modules</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/physical-ai-book/docs/intro">Getting Started</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a class="navbar__item navbar__link" href="/physical-ai-book/chat">AI Assistant</a><a class="navbar__item navbar__link" href="/physical-ai-book/cyberpunk-demo">Cyberpunk Demo</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Meta+k)" aria-keyshortcuts="Meta+k"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 24 24" aria-hidden="true"><circle cx="11" cy="11" r="8" stroke="currentColor" fill="none" stroke-width="1.4"></circle><path d="m21 21-4.3-4.3" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/physical-ai-book/docs/intro"><span title="Introduction" class="categoryLinkLabel_W154">Introduction</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/intro"><span title="Physical AI &amp; Humanoid Robotics" class="linkLabel_WmDU">Physical AI &amp; Humanoid Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/prerequisites"><span title="Prerequisites Checklist" class="linkLabel_WmDU">Prerequisites Checklist</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/setup"><span title="Setup Guide" class="linkLabel_WmDU">Setup Guide</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/physical-ai-book/docs/module1-ros2/introduction"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module1-ros2/introduction"><span title="Introduction to ROS 2" class="linkLabel_WmDU">Introduction to ROS 2</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module1-ros2/core-concepts"><span title="Core Concepts: Nodes, Topics, Services" class="linkLabel_WmDU">Core Concepts: Nodes, Topics, Services</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module1-ros2/first-node"><span title="Your First ROS 2 Node" class="linkLabel_WmDU">Your First ROS 2 Node</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module1-ros2/python-rclpy"><span title="Python Integration with rclpy" class="linkLabel_WmDU">Python Integration with rclpy</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module1-ros2/urdf"><span title="URDF for Humanoid Robots" class="linkLabel_WmDU">URDF for Humanoid Robots</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module1-ros2/project"><span title="Project: Voice-Controlled Robot Arm" class="linkLabel_WmDU">Project: Voice-Controlled Robot Arm</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module1-ros2/assessment"><span title="Module 1 Assessment" class="linkLabel_WmDU">Module 1 Assessment</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/physical-ai-book/docs/module2-simulation/introduction"><span title="Module 2: The Digital Twin (Gazebo &amp; Unity)" class="categoryLinkLabel_W154">Module 2: The Digital Twin (Gazebo &amp; Unity)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module2-simulation/introduction"><span title="Introduction to Robot Simulation" class="linkLabel_WmDU">Introduction to Robot Simulation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module2-simulation/gazebo-fundamentals"><span title="Gazebo Fundamentals" class="linkLabel_WmDU">Gazebo Fundamentals</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module2-simulation/simulating-sensors"><span title="Simulating Sensors (LiDAR, Cameras, IMU)" class="linkLabel_WmDU">Simulating Sensors (LiDAR, Cameras, IMU)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module2-simulation/unity-rendering"><span title="Unity for High-Fidelity Rendering" class="linkLabel_WmDU">Unity for High-Fidelity Rendering</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module2-simulation/building-environments"><span title="Building Test Environments" class="linkLabel_WmDU">Building Test Environments</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module2-simulation/project"><span title="Project: Autonomous Navigation in Simulation" class="linkLabel_WmDU">Project: Autonomous Navigation in Simulation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module2-simulation/assessment"><span title="Module 2 Assessment" class="linkLabel_WmDU">Module 2 Assessment</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/physical-ai-book/docs/module3-isaac/introduction"><span title="Module 3: The AI-Robot Brain (NVIDIA Isaac)" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain (NVIDIA Isaac)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module3-isaac/introduction"><span title="Introduction to NVIDIA Isaac" class="linkLabel_WmDU">Introduction to NVIDIA Isaac</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module3-isaac/isaac-sim"><span title="Isaac Sim Deep Dive" class="linkLabel_WmDU">Isaac Sim Deep Dive</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module3-isaac/visual-slam"><span title="Visual SLAM with Isaac ROS" class="linkLabel_WmDU">Visual SLAM with Isaac ROS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module3-isaac/navigation-stack"><span title="Navigation Stack (Nav2) with Isaac" class="linkLabel_WmDU">Navigation Stack (Nav2) with Isaac</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module3-isaac/perception-pipeline"><span title="Perception Pipeline with Isaac" class="linkLabel_WmDU">Perception Pipeline with Isaac</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module3-isaac/project"><span title="Project: Warehouse Robot with Isaac" class="linkLabel_WmDU">Project: Warehouse Robot with Isaac</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module3-isaac/assessment"><span title="Module 3 Assessment" class="linkLabel_WmDU">Module 3 Assessment</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/physical-ai-book/docs/module4-vla/llms-robotics"><span title="Module 4: Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module4-vla/llms-robotics"><span title="LLMs Meet Robotics" class="linkLabel_WmDU">LLMs Meet Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module4-vla/voice-action-pipeline"><span title="Voice-to-Action Pipeline" class="linkLabel_WmDU">Voice-to-Action Pipeline</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module4-vla/cognitive-planning"><span title="Cognitive Planning with LLMs" class="linkLabel_WmDU">Cognitive Planning with LLMs</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module4-vla/multimodal-integration"><span title="Multimodal Integration" class="linkLabel_WmDU">Multimodal Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module4-vla/capstone"><span title="CAPSTONE: Autonomous Humanoid Assistant" class="linkLabel_WmDU">CAPSTONE: Autonomous Humanoid Assistant</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module4-vla/advanced-topics"><span title="Advanced Topics in VLA Systems" class="linkLabel_WmDU">Advanced Topics in VLA Systems</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/module4-vla/final-assessment"><span title="Module 4 Final Assessment" class="linkLabel_WmDU">Module 4 Final Assessment</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/physical-ai-book/docs/appendices/installation-guides"><span title="Appendices" class="categoryLinkLabel_W154">Appendices</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/appendices/installation-guides"><span title="Appendix A: Installation Guides" class="linkLabel_WmDU">Appendix A: Installation Guides</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/appendices/ros2-command-reference"><span title="Appendix B: ROS 2 Command Reference" class="linkLabel_WmDU">Appendix B: ROS 2 Command Reference</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/appendices/python-libraries-reference"><span title="Appendix C: Python Libraries Reference" class="linkLabel_WmDU">Appendix C: Python Libraries Reference</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-book/docs/appendices/resources-links"><span title="Appendix D: Resources and Links" class="linkLabel_WmDU">Appendix D: Resources and Links</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/physical-ai-book/docs/appendices/glossary"><span title="Appendix E: Glossary" class="linkLabel_WmDU">Appendix E: Glossary</span></a></li></ul></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/physical-ai-book/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Appendices</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Appendix E: Glossary</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Appendix E: Glossary</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="a">A<a href="#a" class="hash-link" aria-label="Direct link to A" title="Direct link to A" translate="no">​</a></h2>
<p><strong>Action Space</strong>: The set of all possible actions that an agent can take in an environment. In robotics, this includes all possible movements, manipulations, or other behaviors the robot can perform.</p>
<p><strong>Affordance</strong>: A property of an object or environment that indicates what actions are possible for an agent. For example, a handle affords grasping, a button affords pressing.</p>
<p><strong>AI Foundation Model</strong>: A large-scale AI model trained on diverse data that can be adapted to various downstream tasks. Examples include GPT for language and DALL-E for vision.</p>
<p><strong>Articulated Robot</strong>: A robot composed of multiple rigid bodies connected by joints, allowing for complex movements. Examples include robotic arms and humanoid robots.</p>
<p><strong>Autonomous System</strong>: A system capable of performing tasks without direct human intervention, often incorporating AI for decision-making and adaptation.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="b">B<a href="#b" class="hash-link" aria-label="Direct link to B" title="Direct link to B" translate="no">​</a></h2>
<p><strong>Behavior Tree</strong>: A hierarchical structure used in robotics and AI to represent and execute complex behaviors. It provides a way to organize and control the execution of tasks.</p>
<p><strong>Biomechanics</strong>: The study of the structure, function, and motion of the mechanical aspects of biological systems, particularly relevant for humanoid robotics.</p>
<p><strong>Blob Detection</strong>: A computer vision technique for detecting connected regions of pixels that share similar properties, often used for object detection in robotics.</p>
<p><strong>Bounded Rationality</strong>: The idea that decision-making is limited by available information, cognitive limitations, and time constraints, which is crucial for physical AI systems operating in real-time.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="c">C<a href="#c" class="hash-link" aria-label="Direct link to C" title="Direct link to C" translate="no">​</a></h2>
<p><strong>Categorical Perception</strong>: The phenomenon where continuous physical stimuli are perceived as discrete categories, important for how robots categorize objects and environments.</p>
<p><strong>Cognitive Architecture</strong>: A blueprint for intelligent agents, specifying the structure of memory, modules, and operations that enable intelligent behavior.</p>
<p><strong>Commonsense Reasoning</strong>: The ability to make sound judgments and inferences about everyday situations without formal training, essential for robots operating in human environments.</p>
<p><strong>Computer Vision</strong>: A field of artificial intelligence that trains computers to interpret and understand the visual world, crucial for physical AI perception.</p>
<p><strong>Continual Learning</strong>: The ability of a model to learn new tasks without forgetting previous ones, important for robots that must adapt to new situations over time.</p>
<p><strong>Convolutional Neural Network (CNN)</strong>: A class of deep neural networks commonly used for analyzing visual imagery, widely used in robotics for perception tasks.</p>
<p><strong>Cross-Modal Learning</strong>: Learning that involves multiple sensory modalities (e.g., vision and language), important for physical AI systems that must integrate different types of information.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="d">D<a href="#d" class="hash-link" aria-label="Direct link to D" title="Direct link to D" translate="no">​</a></h2>
<p><strong>Deep Learning</strong>: A subset of machine learning based on artificial neural networks with representation learning, fundamental to modern physical AI systems.</p>
<p><strong>Deep Reinforcement Learning</strong>: A combination of deep learning and reinforcement learning where neural networks approximate value functions or policies, used for robot control and navigation.</p>
<p><strong>Dexterity</strong>: The skill and grace of physical movement, especially of the hands and fingers, important for robotic manipulation.</p>
<p><strong>Differentiable Physics</strong>: Physics simulation that allows gradients to flow through the simulation for learning, enabling end-to-end training of physical AI systems.</p>
<p><strong>Digital Twin</strong>: A virtual replica of a physical system that serves as a real-time digital counterpart, used for simulation and testing of physical AI systems.</p>
<p><strong>Domain Randomization</strong>: A technique for training neural networks by randomizing simulation environments to improve transfer to real-world scenarios.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="e">E<a href="#e" class="hash-link" aria-label="Direct link to E" title="Direct link to E" translate="no">​</a></h2>
<p><strong>Embodied AI</strong>: Artificial intelligence that is grounded in physical interaction with the world, where the body plays a crucial role in intelligence.</p>
<p><strong>Embodied Cognition</strong>: The theory that many features of cognition are shaped by aspects of the body beyond the brain, relevant to physical AI design.</p>
<p><strong>Episodic Memory</strong>: A form of long-term memory that records personal experiences and events, which can be implemented in physical AI systems for learning from experience.</p>
<p><strong>Euclidean Distance</strong>: The straight-line distance between two points in Euclidean space, commonly used in robotics for path planning and navigation.</p>
<p><strong>Explainable AI (XAI)</strong>: Artificial intelligence that can explain its decisions and actions to human users, important for trust in physical AI systems.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="f">F<a href="#f" class="hash-link" aria-label="Direct link to F" title="Direct link to F" translate="no">​</a></h2>
<p><strong>Feature Detection</strong>: The process of computing representations of image features of interest, fundamental to computer vision in robotics.</p>
<p><strong>Field of View (FOV)</strong>: The extent of the observable world that is seen at any given moment, important for sensor configuration in robotics.</p>
<p><strong>Fine-Tuning</strong>: The process of further training a pre-trained model on a specific task, commonly used to adapt foundation models for robotics applications.</p>
<p><strong>Forward Kinematics</strong>: The process of determining the position and orientation of the end-effector given the joint angles, fundamental to robot control.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="g">G<a href="#g" class="hash-link" aria-label="Direct link to G" title="Direct link to G" translate="no">​</a></h2>
<p><strong>Gaussian Process</strong>: A stochastic process used for regression and classification, applicable to uncertainty quantification in robotics.</p>
<p><strong>Generalization</strong>: The ability of a model to perform well on unseen data, crucial for physical AI systems operating in diverse environments.</p>
<p><strong>Generative Adversarial Network (GAN)</strong>: A class of machine learning frameworks designed for generating new data, used in robotics for simulation and planning.</p>
<p><strong>Grounding</strong>: The process of connecting abstract symbols or concepts to perceptual experience, essential for physical AI systems that must connect language to physical actions.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="h">H<a href="#h" class="hash-link" aria-label="Direct link to H" title="Direct link to H" translate="no">​</a></h2>
<p><strong>Haptic Feedback</strong>: The use of touch sensations to provide information to a user, important for human-robot interaction.</p>
<p><strong>Human-Robot Interaction (HRI)</strong>: The study of interactions between humans and robots, focusing on design and implementation of robots for human environments.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="i">I<a href="#i" class="hash-link" aria-label="Direct link to I" title="Direct link to I" translate="no">​</a></h2>
<p><strong>Imitation Learning</strong>: Learning by observing and mimicking the behavior of others, used in robotics for teaching complex behaviors.</p>
<p><strong>Information Gain</strong>: The expected reduction in entropy caused by partitioning the examples according to a given attribute, used in active learning for robotics.</p>
<p><strong>Inverse Kinematics</strong>: The process of determining joint angles needed to achieve a desired end-effector position, fundamental to robot manipulation.</p>
<p><strong>Isaac Sim</strong>: NVIDIA&#x27;s simulation environment for robotics, AI, and autonomous systems, designed for training and testing physical AI systems.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="j">J<a href="#j" class="hash-link" aria-label="Direct link to J" title="Direct link to J" translate="no">​</a></h2>
<p><strong>Joint Space</strong>: The space defined by the joint angles of a robot manipulator, used for robot control and planning.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="k">K<a href="#k" class="hash-link" aria-label="Direct link to K" title="Direct link to K" translate="no">​</a></h2>
<p><strong>Kinematics</strong>: The branch of mechanics concerned with the motion of objects without reference to the forces that cause the motion, fundamental to robotics.</p>
<p><strong>Knowledge Representation</strong>: An area in artificial intelligence dedicated to representing information about the world in a form that a computer can utilize, important for physical AI reasoning.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="l">L<a href="#l" class="hash-link" aria-label="Direct link to L" title="Direct link to L" translate="no">​</a></h2>
<p><strong>Language Model</strong>: A probability distribution over sequences of words, increasingly important for commanding physical AI systems through natural language.</p>
<p><strong>Learning Rate</strong>: A hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated, important for training physical AI systems.</p>
<p><strong>LiDAR</strong>: Light Detection and Ranging, a remote sensing method that uses light in the form of a pulsed laser to measure distances, widely used in robotics for navigation and mapping.</p>
<p><strong>Long Short-Term Memory (LSTM)</strong>: A type of recurrent neural network that can learn long-term dependencies, used in robotics for sequence modeling and control.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="m">M<a href="#m" class="hash-link" aria-label="Direct link to M" title="Direct link to M" translate="no">​</a></h2>
<p><strong>Manipulandum</strong>: An object that is manipulated by a person or robot, important in the study of robotic manipulation.</p>
<p><strong>Manifold Learning</strong>: A class of unsupervised learning algorithms for dimensionality reduction, applicable to high-dimensional sensor data in robotics.</p>
<p><strong>Mechanical Advantage</strong>: The factor by which a mechanism multiplies the force put into it, relevant to robot design and actuator selection.</p>
<p><strong>Meta-Learning</strong>: Learning to learn, where a model learns how to adapt quickly to new tasks, important for robots that must adapt to new environments.</p>
<p><strong>Multimodal Integration</strong>: The process of combining information from multiple sensory modalities, crucial for physical AI systems that must understand their environment comprehensively.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="n">N<a href="#n" class="hash-link" aria-label="Direct link to N" title="Direct link to N" translate="no">​</a></h2>
<p><strong>Navigation Mesh</strong>: A data structure that represents the walkable areas of a game world or environment, used in robotics for path planning.</p>
<p><strong>Neural Radiance Fields (NeRF)</strong>: A method for synthesizing novel views of complex 3D scenes from a sparse set of images, increasingly used in robotics for scene understanding.</p>
<p><strong>Non-Holonomic Constraint</strong>: A constraint that cannot be integrated to give a constraint on positions alone, relevant to wheeled robot motion planning.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="o">O<a href="#o" class="hash-link" aria-label="Direct link to O" title="Direct link to O" translate="no">​</a></h2>
<p><strong>Occupancy Grid</strong>: A probabilistic representation of space that discretizes the environment into a grid of occupied/free cells, fundamental to robot navigation.</p>
<p><strong>Operational Space</strong>: The space in which the end-effector of a robot operates, used for motion planning and control.</p>
<p><strong>Overfitting</strong>: When a model learns the training data too well, including noise and details that don&#x27;t generalize, a problem in training physical AI systems.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="p">P<a href="#p" class="hash-link" aria-label="Direct link to P" title="Direct link to P" translate="no">​</a></h2>
<p><strong>Part Affordance</strong>: The relationship between an object part and the actions it affords, important for robotic manipulation.</p>
<p><strong>Path Planning</strong>: The process of determining a route from a start point to a goal point, fundamental to robot navigation.</p>
<p><strong>Perceptual Binding</strong>: The process of combining different features of an object into a coherent percept, relevant to robot perception.</p>
<p><strong>Phase Space</strong>: A space in which all possible states of a system are represented, used in robotics for motion planning.</p>
<p><strong>Phenomenology</strong>: The study of structures of consciousness as experienced from the first-person point of view, relevant to understanding robot perception.</p>
<p><strong>Point Cloud</strong>: A collection of data points in space, typically representing the external surface of an object, used in robotics for 3D scene understanding.</p>
<p><strong>Probabilistic Robotics</strong>: A branch of robotics that deals with uncertainty in sensing and actuation, fundamental to real-world physical AI systems.</p>
<p><strong>Proxemics</strong>: The study of human use of space and the effects that population density has on behavior, relevant to human-robot interaction.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="q">Q<a href="#q" class="hash-link" aria-label="Direct link to Q" title="Direct link to Q" translate="no">​</a></h2>
<p><strong>Quaternion</strong>: A number system that extends the complex numbers, commonly used for representing rotations in robotics and 3D graphics.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="r">R<a href="#r" class="hash-link" aria-label="Direct link to R" title="Direct link to R" translate="no">​</a></h2>
<p><strong>Reachability</strong>: The ability of a robot to reach a given position in space, fundamental to manipulation planning.</p>
<p><strong>Recurrent Neural Network (RNN)</strong>: A class of artificial neural networks where connections between nodes form a directed graph with connections pointing backward, used in robotics for sequence modeling.</p>
<p><strong>Reinforcement Learning</strong>: A type of machine learning where an agent learns to behave in an environment by performing actions and seeing the results, increasingly used in robotics.</p>
<p><strong>Representation Learning</strong>: Learning representations of data that make it easier to extract useful information for downstream tasks, fundamental to modern physical AI.</p>
<p><strong>Robot Operating System (ROS)</strong>: Flexible framework for writing robot software, providing services designed for heterogeneous computer clusters.</p>
<p><strong>Robotics Middleware</strong>: Software that provides services for communication between different components of a robot system, such as ROS.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="s">S<a href="#s" class="hash-link" aria-label="Direct link to S" title="Direct link to S" translate="no">​</a></h2>
<p><strong>Scene Graph</strong>: A collection of nodes in a graph structure that represents the spatial relationship between objects, used in robotics simulation and visualization.</p>
<p><strong>Semi-Supervised Learning</strong>: A class of machine learning that combines a small amount of labeled data with a large amount of unlabeled data, applicable to robotics where labeled data is expensive.</p>
<p><strong>Sensor Fusion</strong>: The combining of sensory data or data derived from disparate sources such that the resulting information has less uncertainty, crucial for physical AI perception.</p>
<p><strong>Sequential Decision Making</strong>: The process of making a series of decisions over time to achieve a long-term goal, fundamental to robot autonomy.</p>
<p><strong>Sim-to-Real Transfer</strong>: The process of transferring knowledge learned in simulation to real-world applications, a key challenge in robotics.</p>
<p><strong>SLAM (Simultaneous Localization and Mapping)</strong>: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent&#x27;s location, fundamental to robot autonomy.</p>
<p><strong>Social Robot</strong>: A robot that interacts and communicates with humans or other robots using social signals, relevant to human-robot interaction.</p>
<p><strong>Spatial Reasoning</strong>: The cognitive process of acquiring and using knowledge about objects and actions in space, fundamental to physical AI.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="t">T<a href="#t" class="hash-link" aria-label="Direct link to T" title="Direct link to T" translate="no">​</a></h2>
<p><strong>Task and Motion Planning (TAMP)</strong>: An integrated approach to planning at both the task and motion levels, important for complex robotic behaviors.</p>
<p><strong>Temporal Difference Learning</strong>: A prediction-based machine learning method, used in robotics for learning value functions.</p>
<p><strong>Thompson Sampling</strong>: A heuristic for choosing actions that addresses the exploration-exploitation dilemma, applicable to robot learning.</p>
<p><strong>Transform Coding</strong>: A technique for data compression involving mathematical transforms, used in robotics for efficient sensor data processing.</p>
<p><strong>Turing Test</strong>: A test of a machine&#x27;s ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human, relevant to physical AI evaluation.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="u">U<a href="#u" class="hash-link" aria-label="Direct link to U" title="Direct link to U" translate="no">​</a></h2>
<p><strong>Unsupervised Learning</strong>: A type of algorithm that learns patterns from unlabeled data, applicable to robotics for discovering structure in sensor data.</p>
<p><strong>Universal Approximator</strong>: A mathematical function that can approximate any continuous function to arbitrary precision, relevant to neural network design in robotics.</p>
<p><strong>URDF (Unified Robot Description Format)</strong>: An XML format for representing a robot model, used in ROS for robot description.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="v">V<a href="#v" class="hash-link" aria-label="Direct link to V" title="Direct link to V" translate="no">​</a></h2>
<p><strong>Vanishing Gradient Problem</strong>: The issue where gradients become increasingly small as they propagate backward through a neural network, affecting training of deep networks in robotics.</p>
<p><strong>Variable Impedance Control</strong>: Control that allows the robot&#x27;s impedance to be adjusted based on the task requirements, important for safe human-robot interaction.</p>
<p><strong>Variational Autoencoder (VAE)</strong>: A generative model that learns to encode data into a latent space and decode it back, used in robotics for learning representations.</p>
<p><strong>Visual Servoing</strong>: The control of a robot using visual feedback, fundamental to vision-based robot control.</p>
<p><strong>Vision-Language-Action (VLA)</strong>: A framework that integrates visual perception, language understanding, and physical action, representing the current state-of-the-art in physical AI.</p>
<p><strong>Vision-Language Models (VLM)</strong>: Models that jointly understand visual and textual information, increasingly important for commanding robots through natural language.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="w">W<a href="#w" class="hash-link" aria-label="Direct link to W" title="Direct link to W" translate="no">​</a></h2>
<p><strong>Workspace</strong>: The space within which a robot can operate, important for motion planning and task execution.</p>
<p><strong>World Coordinate System</strong>: A fixed coordinate system used as a reference for all other coordinate systems in a robotic application.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="x">X<a href="#x" class="hash-link" aria-label="Direct link to X" title="Direct link to X" translate="no">​</a></h2>
<p><strong>XR (Extended Reality)</strong>: An umbrella term encompassing virtual reality (VR), augmented reality (AR), and mixed reality (MR), increasingly used for robot teleoperation and programming.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="y">Y<a href="#y" class="hash-link" aria-label="Direct link to Y" title="Direct link to Y" translate="no">​</a></h2>
<p><strong>Yaw</strong>: The rotation of an object about its vertical axis, one of the three rotational degrees of freedom in robotics.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="z">Z<a href="#z" class="hash-link" aria-label="Direct link to Z" title="Direct link to Z" translate="no">​</a></h2>
<p><strong>Zero-Shot Learning</strong>: The ability to recognize objects or perform tasks without having seen examples during training, important for robots operating in novel environments.</p>
<p><strong>ZMP (Zero Moment Point)</strong>: A concept used in robotics and biomechanics to aid in the analysis and control of legged locomotion.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="acronyms-and-abbreviations">Acronyms and Abbreviations<a href="#acronyms-and-abbreviations" class="hash-link" aria-label="Direct link to Acronyms and Abbreviations" title="Direct link to Acronyms and Abbreviations" translate="no">​</a></h2>
<p><strong>AI</strong>: Artificial Intelligence</p>
<p><strong>API</strong>: Application Programming Interface</p>
<p><strong>CNN</strong>: Convolutional Neural Network</p>
<p><strong>CPU</strong>: Central Processing Unit</p>
<p><strong>CUDA</strong>: Compute Unified Device Architecture (NVIDIA parallel computing platform)</p>
<p><strong>CV</strong>: Computer Vision</p>
<p><strong>DNN</strong>: Deep Neural Network</p>
<p><strong>GAN</strong>: Generative Adversarial Network</p>
<p><strong>GPU</strong>: Graphics Processing Unit</p>
<p><strong>GUI</strong>: Graphical User Interface</p>
<p><strong>HRI</strong>: Human-Robot Interaction</p>
<p><strong>IDE</strong>: Integrated Development Environment</p>
<p><strong>IoT</strong>: Internet of Things</p>
<p><strong>JSON</strong>: JavaScript Object Notation</p>
<p><strong>LIDAR</strong>: Light Detection and Ranging</p>
<p><strong>LLM</strong>: Large Language Model</p>
<p><strong>ML</strong>: Machine Learning</p>
<p><strong>NLP</strong>: Natural Language Processing</p>
<p><strong>NVMe</strong>: Non-Volatile Memory Express</p>
<p><strong>OOP</strong>: Object-Oriented Programming</p>
<p><strong>PID</strong>: Proportional-Integral-Derivative (controller)</p>
<p><strong>RAM</strong>: Random Access Memory</p>
<p><strong>RNN</strong>: Recurrent Neural Network</p>
<p><strong>ROS</strong>: Robot Operating System</p>
<p><strong>SLAM</strong>: Simultaneous Localization and Mapping</p>
<p><strong>SOTA</strong>: State-of-the-Art</p>
<p><strong>SSL</strong>: Semi-Supervised Learning</p>
<p><strong>TCP</strong>: Transmission Control Protocol</p>
<p><strong>UDP</strong>: User Datagram Protocol</p>
<p><strong>UI</strong>: User Interface</p>
<p><strong>USB</strong>: Universal Serial Bus</p>
<p><strong>UX</strong>: User Experience</p>
<p><strong>VLA</strong>: Vision-Language-Action</p>
<p><strong>VRAM</strong>: Video Random Access Memory</p>
<p><strong>XML</strong>: eXtensible Markup Language</p>
<p><strong>YAML</strong>: YAML Ain&#x27;t Markup Language</p>
<p><strong>ZMP</strong>: Zero Moment Point</p>
<hr>
<p>This glossary provides definitions for key terms used throughout the Physical AI and robotics literature. Understanding these terms is essential for navigating the complex interdisciplinary field that combines robotics, AI, computer vision, and cognitive science.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/syedaareebashah/physical-ai-book/edit/main/docs/appendices/glossary.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/physical-ai-book/docs/appendices/resources-links"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Appendix D: Resources and Links</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#a" class="table-of-contents__link toc-highlight">A</a></li><li><a href="#b" class="table-of-contents__link toc-highlight">B</a></li><li><a href="#c" class="table-of-contents__link toc-highlight">C</a></li><li><a href="#d" class="table-of-contents__link toc-highlight">D</a></li><li><a href="#e" class="table-of-contents__link toc-highlight">E</a></li><li><a href="#f" class="table-of-contents__link toc-highlight">F</a></li><li><a href="#g" class="table-of-contents__link toc-highlight">G</a></li><li><a href="#h" class="table-of-contents__link toc-highlight">H</a></li><li><a href="#i" class="table-of-contents__link toc-highlight">I</a></li><li><a href="#j" class="table-of-contents__link toc-highlight">J</a></li><li><a href="#k" class="table-of-contents__link toc-highlight">K</a></li><li><a href="#l" class="table-of-contents__link toc-highlight">L</a></li><li><a href="#m" class="table-of-contents__link toc-highlight">M</a></li><li><a href="#n" class="table-of-contents__link toc-highlight">N</a></li><li><a href="#o" class="table-of-contents__link toc-highlight">O</a></li><li><a href="#p" class="table-of-contents__link toc-highlight">P</a></li><li><a href="#q" class="table-of-contents__link toc-highlight">Q</a></li><li><a href="#r" class="table-of-contents__link toc-highlight">R</a></li><li><a href="#s" class="table-of-contents__link toc-highlight">S</a></li><li><a href="#t" class="table-of-contents__link toc-highlight">T</a></li><li><a href="#u" class="table-of-contents__link toc-highlight">U</a></li><li><a href="#v" class="table-of-contents__link toc-highlight">V</a></li><li><a href="#w" class="table-of-contents__link toc-highlight">W</a></li><li><a href="#x" class="table-of-contents__link toc-highlight">X</a></li><li><a href="#y" class="table-of-contents__link toc-highlight">Y</a></li><li><a href="#z" class="table-of-contents__link toc-highlight">Z</a></li><li><a href="#acronyms-and-abbreviations" class="table-of-contents__link toc-highlight">Acronyms and Abbreviations</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Modules</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical-ai-book/docs/module1-ros2/introduction">Module 1: Robotic Nervous System (ROS 2)</a></li><li class="footer__item"><a class="footer__link-item" href="/physical-ai-book/docs/module2-simulation/introduction">Module 2: Digital Twin (Gazebo &amp; Unity)</a></li><li class="footer__item"><a class="footer__link-item" href="/physical-ai-book/docs/module3-isaac/introduction">Module 3: AI-Robot Brain (NVIDIA Isaac)</a></li><li class="footer__item"><a class="footer__link-item" href="/physical-ai-book/docs/module4-vla/llms-robotics">Module 4: Vision-Language-Action (VLA)</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://docs.omniverse.nvidia.com/isaacsim/latest/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Isaac Sim<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://docs.ros.org/en/humble/" target="_blank" rel="noopener noreferrer" class="footer__link-item">ROS 2 Humble<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://nvidia-isaac-ros.github.io/" target="_blank" rel="noopener noreferrer" class="footer__link-item">NVIDIA Isaac ROS<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://gazebosim.org/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Gazebo Sim<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discourse.ros.org/" target="_blank" rel="noopener noreferrer" class="footer__link-item">ROS Discourse<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://forums.developer.nvidia.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">NVIDIA Developer Forum<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://robotics.stackexchange.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Robotics Stack Exchange<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://embodied-ai.org/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Physical AI Research<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics. Built with Docusaurus for the Physical AI Community.</div></div></div></footer></div>
</body>
</html>