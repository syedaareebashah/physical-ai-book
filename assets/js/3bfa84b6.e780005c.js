"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[8171],{4600:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>t,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"appendices/bibliography","title":"Appendix F: Bibliography and References","description":"Table of Contents","source":"@site/docs/appendices/bibliography.md","sourceDirName":"appendices","slug":"/appendices/bibliography","permalink":"/physical-ai-book/docs/appendices/bibliography","draft":false,"unlisted":false,"editUrl":"https://github.com/syedaareebashah/physical-ai-book/edit/main/docs/appendices/bibliography.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6}}');var r=i(4848),l=i(8453);const o={sidebar_position:6},a="Appendix F: Bibliography and References",t={},c=[{value:"Table of Contents",id:"table-of-contents",level:2},{value:"Foundational Papers",id:"foundational-papers",level:2},{value:"Physical AI and Embodied Intelligence",id:"physical-ai-and-embodied-intelligence",level:2},{value:"Vision-Language-Action (VLA) Systems",id:"vision-language-action-vla-systems",level:2},{value:"Robotics and Navigation",id:"robotics-and-navigation",level:2},{value:"Isaac and NVIDIA Technologies",id:"isaac-and-nvidia-technologies",level:2},{value:"ROS 2 and Middleware",id:"ros-2-and-middleware",level:2},{value:"Simulation and Digital Twins",id:"simulation-and-digital-twins",level:2},{value:"Machine Learning for Robotics",id:"machine-learning-for-robotics",level:2},{value:"Computer Vision and Perception",id:"computer-vision-and-perception",level:2},{value:"Human-Robot Interaction",id:"human-robot-interaction",level:2},{value:"Online Resources",id:"online-resources",level:2},{value:"Official Documentation",id:"official-documentation",level:3},{value:"Research Repositories",id:"research-repositories",level:3},{value:"Development Tools",id:"development-tools",level:3},{value:"Conferences and Journals",id:"conferences-and-journals",level:3},{value:"Educational Resources",id:"educational-resources",level:3},{value:"Simulation Platforms",id:"simulation-platforms",level:3},{value:"AI and Machine Learning",id:"ai-and-machine-learning",level:3},{value:"Community and Support",id:"community-and-support",level:3},{value:"Industry Applications",id:"industry-applications",level:3},{value:"Hardware and Sensors",id:"hardware-and-sensors",level:3},{value:"Datasets and Benchmarks",id:"datasets-and-benchmarks",level:3},{value:"Tutorials and Courses",id:"tutorials-and-courses",level:3}];function d(n){const e={a:"a",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",ul:"ul",...(0,l.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"appendix-f-bibliography-and-references",children:"Appendix F: Bibliography and References"})}),"\n",(0,r.jsx)(e.h2,{id:"table-of-contents",children:"Table of Contents"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"#foundational-papers",children:"Foundational Papers"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"#physical-ai-and-embodied-intelligence",children:"Physical AI and Embodied Intelligence"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"#vision-language-action-vla-systems",children:"Vision-Language-Action (VLA) Systems"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"#robotics-and-navigation",children:"Robotics and Navigation"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"#isaac-and-nvidia-technologies",children:"Isaac and NVIDIA Technologies"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"#ros-2-and-middleware",children:"ROS 2 and Middleware"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"#simulation-and-digital-twins",children:"Simulation and Digital Twins"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"#machine-learning-for-robotics",children:"Machine Learning for Robotics"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"#computer-vision-and-perception",children:"Computer Vision and Perception"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"#human-robot-interaction",children:"Human-Robot Interaction"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"#online-resources",children:"Online Resources"})}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"foundational-papers",children:"Foundational Papers"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Brooks, R. A. (1991). Intelligence without representation. ",(0,r.jsx)(e.em,{children:"Artificial Intelligence"}),", 47(1-3), 139-159."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Classic paper on behavior-based robotics and the importance of embodiment"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Pfeifer, R., & Bongard, J. (2006). ",(0,r.jsx)(e.em,{children:"How the body shapes the way we think: A new view of intelligence"}),". MIT Press."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Foundational work on embodied cognition and morphological computation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Clark, A., & Chalmers, D. (1998). The extended mind. ",(0,r.jsx)(e.em,{children:"Analysis"}),", 58(1), 7-19."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Philosophical foundation for understanding how tools and environment extend cognition"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Gibson, J. J. (1979). ",(0,r.jsx)(e.em,{children:"The ecological approach to visual perception"}),". Houghton Mifflin."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Introduced the concept of affordances, crucial for Physical AI"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Minsky, M. (1986). ",(0,r.jsx)(e.em,{children:"The society of mind"}),". Simon and Schuster."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Early work on distributed intelligence, relevant to multi-modal AI systems"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"physical-ai-and-embodied-intelligence",children:"Physical AI and Embodied Intelligence"}),"\n",(0,r.jsxs)(e.ol,{start:"6",children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["B\xfclthoff, H. H., Mohler, B. J., Newell, F. N., & Thornton, I. M. (Eds.). (2002). ",(0,r.jsx)(e.em,{children:"Human perception of objects: Early and high-level vision"}),". Psychology Press."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Understanding how biological systems perceive and interact with objects"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Lakoff, G., & Johnson, M. (1999). ",(0,r.jsx)(e.em,{children:"Philosophy in the flesh: The embodied mind and its challenge to Western thought"}),". Basic Books."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Philosophical foundations of embodied cognition"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Metta, G., Natale, L., Nori, F., Sandini, G., Vernon, D., Fadiga, L., ... & Tsagarakis, N. (2008). The iCub humanoid robot: An open platform for research in embodied cognition. ",(0,r.jsx)(e.em,{children:"Proceedings of the 8th workshop on performance metrics for intelligent systems"}),", 50-56."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Open platform for embodied cognition research"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Pfeifer, R., Lungarella, M., & Iida, F. (2007). Self-organization, embodiment, and biologically inspired robotics. ",(0,r.jsx)(e.em,{children:"Science"}),", 318(5853), 1088-1093."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"How self-organization and embodiment contribute to intelligence"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Ziemke, T., & Sharkey, N. E. (2001). A stroll through the worlds of robots and humans: Applying Jakob von Uexk\xfcll's anthropomorphic method in cognitive science and robotics. ",(0,r.jsx)(e.em,{children:"Semiotica"}),", 2001(134), 701-719."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Applying biological concepts to robotics and AI"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Pfeifer, R., & Scheier, C. (1999). ",(0,r.jsx)(e.em,{children:"Understanding intelligence"}),". MIT Press."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Comprehensive overview of embodied approaches to intelligence"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Clark, A. (2008). ",(0,r.jsx)(e.em,{children:"Supersizing the mind: Embodiment, action, and cognitive extension"}),". Oxford University Press."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Modern perspective on extended cognition and embodiment"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"vision-language-action-vla-systems",children:"Vision-Language-Action (VLA) Systems"}),"\n",(0,r.jsxs)(e.ol,{start:"13",children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Ahn, M., Brohan, A., Brown, N., Chebotar, Y., Cortes, O., David, B., ... & Vanhoucke, V. (2022). A collaborative embodied AI platform for industrial manipulation. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2209.11916"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Collaborative Physical AI systems for manipulation tasks"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Brohan, A., Brown, N., Carbajal, D., Chebotar, Y., Dabis, J., Finley, P., ... & Welker, K. (2022). RVT: Robotic viewpoint tracking for learning complex manipulation from human demonstrations. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2209.11383"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Viewpoint tracking for human demonstration learning"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Brohan, A., Chebotar, Y., Dabis, J., Finn, C., Gopalakrishnan, K., Jang, K., ... & Zhu, Y. (2022). RT-1: Robotics transformer for real-world control at scale. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2212.06817"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Large-scale transformer for robotics control"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Chen, K., Wu, Y., Gao, S., Wang, H., Su, H., & Zhu, S. C. (2022). Grounding language models to images for multimodal generation. ",(0,r.jsx)(e.em,{children:"International Conference on Machine Learning"}),", 2966-2982."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Connecting language models to visual perception"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Driess, D., Srivastava, R., Stark, M., & Toussaint, M. (2022). Deep embodied intelligence via compositional program induction. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2209.12827"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Program induction for embodied intelligence"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Fan, H., Yang, Y., He, D., Huang, J., Zhao, T., Wang, X., ... & Liu, T. Y. (2022). Flamingo: a visual language model for few-shot learning. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2204.14198"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Few-shot learning for vision-language tasks"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Karaz, M., Prorok, A., & Jawahar, C. V. (2023). RoboFlamingo: Robots learn to act and speak by large video-language models. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2305.17122"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Video-language models for robot action"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Liu, X., Li, H., Zhang, Y., Gu, Y., Duan, H., Wu, Y., ... & Ji, J. (2022). Polyglot: Massively multilingual models. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2203.15555"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Multilingual capabilities for global Physical AI"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Narang, S., Chowdhery, A., Mishra, S., Zhou, Y., Lebanoff, B., Bash, J., ... & Zhou, D. (2022). DoReMi: Optimizing data mixtures speeds up language model pretraining. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2211.15993"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Efficient training for large models"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Parmar, G., Wu, Y., Chen, D., & Yang, J. (2022). VideoPoet: A large language model for zero-shot video generation. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2212.00932"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Video generation for simulation and training"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Patry, M., Lala, D., Huh, M., Park, J., & Oliva, J. (2022). Scaling autoregressive video models. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2212.02833"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Scaling video models for Physical AI"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Reed, S., Zolna, K., Parisotto, E., Colmenarejo, S. G., Novikov, A., Barth-Maron, G., ... & Mohamed, S. (2020). A generalist agent. ",(0,r.jsx)(e.em,{children:"Transactions on Machine Learning Research"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Generalist agents for diverse tasks"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Saharia, C., Chan, W., Saxena, S., Li, L., Whang, J., Denton, E. L., ... & Norouzi, M. (2022). Photorealistic text-to-image diffusion models with deep language understanding. ",(0,r.jsx)(e.em,{children:"Advances in Neural Information Processing Systems"}),", 35, 36479-36494."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Diffusion models for image generation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L., Bastien, S., ... & Silver, D. (2020). Mastering Atari, Go, Chess and Shogi by planning with a learned model. ",(0,r.jsx)(e.em,{children:"Nature"}),", 588(7839), 604-609."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Model-based planning for complex tasks"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Tancik, M., Weber, J. N., Baker, B., Maharaj, T., Casas, S., McAllister, R., ... & Mildenhall, B. (2023). Neural scene representation and rendering. ",(0,r.jsx)(e.em,{children:"Communications of the ACM"}),", 66(6), 92-101."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Neural representations for scene understanding"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., ... & J\xe9gou, H. (2023). Llama: Open and efficient foundation language models. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2302.13971"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Open foundation models"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., ... & Zhou, D. (2022). Generating training data with language models: Towards zero-shot language-to-robot policy transfer. ",(0,r.jsx)(e.em,{children:"Advances in Neural Information Processing Systems"}),", 35, 28836-28849."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Language-to-robot transfer"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Wu, Y., Parmar, G., Huang, B., Chen, D., Girdhar, R., & Yang, J. (2022). Masked conditional video generation via pixel-level control. ",(0,r.jsx)(e.em,{children:"International Conference on Learning Representations"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Conditional video generation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Yamada, I., Shindo, H., Takeda, H., & Takenouchi, T. (2023). Large language models as general pattern machines. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2302.03269"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Pattern recognition in large models"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Yu, T., Zhang, Z., Du, Y., Hu, Z., Chen, X., Lengerich, B. J., Salakhutdinov, R., & Carbonell, J. (2022). EVA: Exploring the limits of masked visual representation learning at scale. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2211.07636"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Scalable visual representation learning"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Zheng, L., Liu, W., Li, J., Qi, X., Han, X., Sun, J., ... & Gao, J. (2022). A survey of vision-language pretrained models. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2202.10936"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Comprehensive survey of vision-language models"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Zhu, Y., Gao, S., Xu, Z., Chen, X., & Zhu, S. C. (2022). Vision-language navigation: A survey. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:2205.13083"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Survey of vision-language navigation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Zhu, Y., Mottaghi, R., Kolve, E., Lim, J. J., Gupta, A., Fei-Fei, L., & Farhadi, A. (2017). Target-driven visual navigation in indoor scenes using deep reinforcement learning. ",(0,r.jsx)(e.em,{children:"Proceedings of the IEEE international conference on robotics and automation"}),", 3357-3364."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Early work on visual navigation"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"robotics-and-navigation",children:"Robotics and Navigation"}),"\n",(0,r.jsxs)(e.ol,{start:"36",children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Fox, D., Burgard, W., & Thrun, S. (1997). The dynamic window approach to collision avoidance. ",(0,r.jsx)(e.em,{children:"IEEE Robotics & Automation Magazine"}),", 4(1), 23-33."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Classic collision avoidance algorithm"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Konolige, K., & Agrawal, M. (2008). Frame-based motion estimation. ",(0,r.jsx)(e.em,{children:"IEEE Transactions on Robotics"}),", 24(6), 1379-1392."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Frame-based motion estimation for robotics"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["K\xfcmmerle, R., Steder, B., Dornhege, C., Ruhnke, M., Grisetti, G., Kleiner, A., & Burgard, W. (2009). On measuring the accuracy of SLAM algorithms. ",(0,r.jsx)(e.em,{children:"Autonomous Robots"}),", 27(4), 387-407."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"SLAM evaluation metrics"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["LaValle, S. M. (2006). ",(0,r.jsx)(e.em,{children:"Planning algorithms"}),". Cambridge University Press."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Comprehensive treatment of motion planning algorithms"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Lynch, K. M., & Park, F. C. (2017). ",(0,r.jsx)(e.em,{children:"Modern robotics: Mechanics, planning, and control"}),". Cambridge University Press."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Modern treatment of robotics fundamentals"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Montiel, J., Civera, J., & Davison, A. J. (2016). Unifying visual-SLAM maps. ",(0,r.jsx)(e.em,{children:"The International Journal of Robotics Research"}),", 35(9), 1008-1018."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Visual SLAM map unification"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Murphy, R. R. (2019). ",(0,r.jsx)(e.em,{children:"Introduction to AI robotics"}),". MIT press."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Comprehensive introduction to AI robotics"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Quigley, M., Conley, K., Gerkey, B., Faust, J., Foote, T., Leibs, J., ... & Ng, A. Y. (2009). ROS: an open-source Robot Operating System. ",(0,r.jsx)(e.em,{children:"ICRA Workshop on Open Source Software"}),", 3(3.2), 5."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Original ROS paper"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Roy, N., & Thrun, S. (1999). Coastal navigation with mobile robots. ",(0,r.jsx)(e.em,{children:"Advances in neural information processing systems"}),", 11, 1043-1049."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Coastal navigation techniques"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Thrun, S., Burgard, W., & Fox, D. (2005). ",(0,r.jsx)(e.em,{children:"Probabilistic robotics"}),". MIT press."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Definitive text on probabilistic robotics"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Vijayanarasimhan, S., Richey, C., Garg, K., Sapp, B., & Anguelov, D. (2017). SFV: Reinforcement learning of physical skills from videos. ",(0,r.jsx)(e.em,{children:"ACM Transactions on Graphics"}),", 36(6), 1-11."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Learning physical skills from video"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"isaac-and-nvidia-technologies",children:"Isaac and NVIDIA Technologies"}),"\n",(0,r.jsxs)(e.ol,{start:"47",children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["NVIDIA Corporation. (2023). ",(0,r.jsx)(e.em,{children:"NVIDIA Isaac Sim User Guide"}),". NVIDIA Developer Documentation."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Official Isaac Sim documentation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["NVIDIA Corporation. (2023). ",(0,r.jsx)(e.em,{children:"Isaac ROS Documentation"}),". NVIDIA Developer Documentation."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Official Isaac ROS documentation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["NVIDIA Corporation. (2023). ",(0,r.jsx)(e.em,{children:"Omniverse Isaac Sim: Robotics Simulation Platform"}),". NVIDIA Developer Documentation."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Omniverse-based robotics simulation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["NVIDIA Corporation. (2023). ",(0,r.jsx)(e.em,{children:"Isaac ROS Visual SLAM Package"}),". NVIDIA GitHub Repository."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"GPU-accelerated Visual SLAM implementation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["NVIDIA Corporation. (2023). ",(0,r.jsx)(e.em,{children:"Isaac ROS Navigation Package"}),". NVIDIA GitHub Repository."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"GPU-accelerated navigation implementation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["NVIDIA Corporation. (2023). ",(0,r.jsx)(e.em,{children:"Isaac ROS Perception Package"}),". NVIDIA GitHub Repository."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"GPU-accelerated perception implementations"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["NVIDIA Corporation. (2023). ",(0,r.jsx)(e.em,{children:"NVIDIA Isaac ROS Gems"}),". NVIDIA GitHub Repository."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Collection of Isaac ROS utilities and examples"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["NVIDIA Corporation. (2023). ",(0,r.jsx)(e.em,{children:"Isaac Lab: Simulation and Learning Framework"}),". NVIDIA Research."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Advanced simulation and learning framework"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["NVIDIA Corporation. (2023). ",(0,r.jsx)(e.em,{children:"Jetson Platform for AI at the Edge"}),". NVIDIA Developer Documentation."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Edge AI platform for robotics"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["NVIDIA Corporation. (2023). ",(0,r.jsx)(e.em,{children:"CUDA Programming Guide"}),". NVIDIA Developer Documentation."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"GPU programming for robotics applications"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"ros-2-and-middleware",children:"ROS 2 and Middleware"}),"\n",(0,r.jsxs)(e.ol,{start:"57",children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Anis, K., Faconti, G., Lewis, C., Lorenz, M., Madsen, J., Penicka, R., ... & Woodall, W. (2019). ",(0,r.jsx)(e.em,{children:"ROS 2 Design Overview"}),". Open Robotics."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Design principles of ROS 2"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Faconti, G., Madsen, J., Woodall, W., Anis, K., Lewis, C., Lorenz, M., & Penicka, R. (2018). ",(0,r.jsx)(e.em,{children:"ROS 2: Towards a Standard Middleware for Robotics"}),". IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"ROS 2 architecture and design"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Macenski, S., & Woodall, W. (2022). ",(0,r.jsx)(e.em,{children:"Navigation: The ROS 2 Navigation System"}),". GitHub Repository Documentation."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Navigation2 system documentation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Quigley, M., Faust, J., & Gerkey, B. (2019). ",(0,r.jsx)(e.em,{children:"ROS 2: The Next Generation of the Robot Operating System"}),". IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"ROS 2 next-generation features"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Woodall, W., Lalancette, S., Pradalier, C., & Quigley, M. (2018). ",(0,r.jsx)(e.em,{children:"ROS 2: Design, architecture, and uses in the wild"}),". arXiv preprint arXiv:1810.07087."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"ROS 2 design and architecture"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"simulation-and-digital-twins",children:"Simulation and Digital Twins"}),"\n",(0,r.jsxs)(e.ol,{start:"62",children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Coumans, E., & Bai, Y. (2016). ",(0,r.jsx)(e.em,{children:"PyBullet, a Python module for physics simulation for games, robotics and machine learning"}),". GitHub Repository."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Physics simulation library"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Koehler, J., Geibel, J., & Wysotzki, F. (2004). ",(0,r.jsx)(e.em,{children:"Reinforcement learning in nondeterministic environments with action model planning"}),". European Conference on Machine Learning."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Reinforcement learning in simulation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Mur-Artal, R., Montiel, J. M. M., & Tard\xf3s, J. D. (2015). ORB-SLAM: a versatile and accurate monocular SLAM system. ",(0,r.jsx)(e.em,{children:"IEEE transactions on robotics"}),", 31(5), 1147-1163."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Monocular SLAM system"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Open Robotics. (2023). ",(0,r.jsx)(e.em,{children:"Gazebo Simulation Platform"}),". Open Robotics Documentation."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Gazebo simulation documentation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Open Robotics. (2023). ",(0,r.jsx)(e.em,{children:"Gazebo Harmonic Documentation"}),". Open Robotics Documentation."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Latest Gazebo documentation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Open Robotics. (2023). ",(0,r.jsx)(e.em,{children:"ROS 2 Gazebo Integration"}),". Open Robotics Documentation."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"ROS 2 and Gazebo integration"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Smith, C., & Harada, K. (2019). ",(0,r.jsx)(e.em,{children:"Unity Robotics: Bringing together the Unity game engine and ROS"}),". IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Unity-ROS integration"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Unity Technologies. (2023). ",(0,r.jsx)(e.em,{children:"Unity Robotics Hub Documentation"}),". Unity Documentation."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Unity robotics tools documentation"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"machine-learning-for-robotics",children:"Machine Learning for Robotics"}),"\n",(0,r.jsxs)(e.ol,{start:"70",children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Abbeel, P., & Ng, A. Y. (2005). Exploration and apprenticeship learning in reinforcement learning. ",(0,r.jsx)(e.em,{children:"Proceedings of the 22nd international conference on Machine learning"}),", 1-8."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Apprenticeship learning for robotics"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Chen, X., Mottaghi, R., Liu, X., Fathi, A., Ordonez, V., & Farhadi, A. (2015). Dawn of the deep learning era in computer vision. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:1502.04939"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Deep learning in computer vision"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Finn, C., Abbeel, P., & Levine, S. (2017). Model-agnostic meta-learning for fast adaptation of deep networks. ",(0,r.jsx)(e.em,{children:"International Conference on Machine Learning"}),", 1126-1135."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Meta-learning for robotics"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Gu, S. S., Holly, E., Lillicrap, T., & Erhan, D. (2017). Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates. ",(0,r.jsx)(e.em,{children:"Proceedings of the IEEE International Conference on Robotics and Automation"}),", 3389-3396."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Deep RL for robotic manipulation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["James, S., Davison, A. J., & Johns, E. (2019). Translating navigation directions in unstructured environments. ",(0,r.jsx)(e.em,{children:"IEEE Robotics and Automation Letters"}),", 4(2), 1029-1036."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Navigation in unstructured environments"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Kalashnikov, D., Irpan, A., Pastor, P., Ibarz, J., Herzog, A., Jang, E., ... & Levine, S. (2018). QT-Opt: Scalable deep reinforcement learning for vision-based robotic manipulation. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:1806.10293"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Vision-based robotic manipulation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Levine, S., Pastor, P., Krizhevsky, A., & Quillen, D. (2016). Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection. ",(0,r.jsx)(e.em,{children:"The International Journal of Robotics Research"}),", 35(4), 421-436."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Hand-eye coordination learning"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Rusu, A. A., Vecerik, M., Roth\xf6rl, T., Heess, N., Pascanu, R., & Hadsell, R. (2016). Sim-to-real robot learning from pixels with progressive nets. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:1610.04286"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Sim-to-real transfer learning"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Sadeghi, F., & Levine, S. (2017). CAD2RL: Real single-image flight without a single real image. ",(0,r.jsx)(e.em,{children:"Proceedings of the IEEE International Conference on Robotics and Automation"}),", 1971-1978."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"CAD-to-RL transfer"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Tai, L., Liu, M., & Boedecker, J. (2016). Learning to navigate with deep gaussian process attention. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:1606.06546"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"GP-based navigation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Zeng, A., Song, S., Nie, B., & Xiao, J. (2018). Robot learning in new environments through accelerated relational reasoning. ",(0,r.jsx)(e.em,{children:"Proceedings of the IEEE International Conference on Robotics and Automation"}),", 1940-1947."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Relational reasoning for robotics"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"computer-vision-and-perception",children:"Computer Vision and Perception"}),"\n",(0,r.jsxs)(e.ol,{start:"81",children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Bradski, G. (2000). The OpenCV Library. ",(0,r.jsx)(e.em,{children:"Dr. Dobb's Journal of Software Tools"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"OpenCV library foundation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Chen, L. C., Zhu, Y., Papandreou, G., Schroff, F., & Adam, H. (2018). Encoder-decoder with atrous separable convolution for semantic image segmentation. ",(0,r.jsx)(e.em,{children:"Proceedings of the European conference on computer vision"}),", 801-818."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Deep semantic segmentation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Girshick, R. (2015). Fast R-CNN. ",(0,r.jsx)(e.em,{children:"Proceedings of the IEEE international conference on computer vision"}),", 1440-1448."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Fast region-based CNN"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["He, K., Gkioxari, G., Doll\xe1r, P., & Girshick, R. (2017). Mask R-CNN. ",(0,r.jsx)(e.em,{children:"Proceedings of the IEEE international conference on computer vision"}),", 2980-2988."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Instance segmentation"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., ... & Darrell, T. (2014). Caffe: Convolutional architecture for fast feature embedding. ",(0,r.jsx)(e.em,{children:"Proceedings of the 22nd ACM international conference on Multimedia"}),", 675-678."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Caffe deep learning framework"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Kingma, D. P., & Ba, J. (2014). Adam: A method for stochastic optimization. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:1412.6980"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Adam optimizer"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Long, J., Shelhamer, E., & Darrell, T. (2015). Fully convolutional networks for semantic segmentation. ",(0,r.jsx)(e.em,{children:"Proceedings of the IEEE conference on computer vision and pattern recognition"}),", 3431-3440."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Fully convolutional networks"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Ren, S., He, K., Girshick, R., & Sun, J. (2015). Faster R-CNN: Towards real-time object detection with region proposal networks. ",(0,r.jsx)(e.em,{children:"Advances in neural information processing systems"}),", 28, 91-99."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Faster region-based CNN"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Redmon, J., Divvala, S., Girshick, R., & Farhadi, A. (2016). You only look once: Unified, real-time object detection. ",(0,r.jsx)(e.em,{children:"Proceedings of the IEEE conference on computer vision and pattern recognition"}),", 779-788."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"YOLO object detection"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., ... & Fei-Fei, L. (2015). ImageNet Large Scale Visual Recognition Challenge. ",(0,r.jsx)(e.em,{children:"International Journal of Computer Vision"}),", 115(3), 211-252."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"ImageNet benchmark"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. ",(0,r.jsx)(e.em,{children:"arXiv preprint arXiv:1409.1556"}),"."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"VGG networks"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., ... & Rabinovich, A. (2015). Going deeper with convolutions. ",(0,r.jsx)(e.em,{children:"Proceedings of the IEEE conference on computer vision and pattern recognition"}),", 1-9."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Inception networks"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. ",(0,r.jsx)(e.em,{children:"Advances in neural information processing systems"}),", 30, 5998-6008."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Transformer architecture"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Yosinski, J., Clune, J., Bengio, Y., & Lipson, H. (2014). How transferable are features in deep neural networks?. ",(0,r.jsx)(e.em,{children:"Advances in neural information processing systems"}),", 27, 3320-3328."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Feature transferability"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"human-robot-interaction",children:"Human-Robot Interaction"}),"\n",(0,r.jsxs)(e.ol,{start:"95",children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Breazeal, C. (2003). ",(0,r.jsx)(e.em,{children:"Toward sociable robots"}),". Robotics and autonomous systems, 42(3-4), 167-175."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Social robotics foundations"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Breazeal, C., Kidd, C. D., Thomaz, A. L., Hoffman, G., & Tellex, S. (2006). Effects of repeated exposure on social perception of a robot. ",(0,r.jsx)(e.em,{children:"Proceedings of the 1st ACM SIGCHI/SIGART conference on Human-robot interaction"}),", 114-120."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Repeated interaction effects"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Fong, T., Nourbakhsh, I., & Dautenhahn, K. (2003). A survey of socially interactive robots. ",(0,r.jsx)(e.em,{children:"Robotics and autonomous systems"}),", 42(3-4), 143-166."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Interactive robotics survey"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Mataric, M. J., & Scassellati, B. (2018). Socially assistive robotics. ",(0,r.jsx)(e.em,{children:"Foundations and trends in robotics"}),", 7(3-4), 219-272."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Assistive robotics"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Mutlu, B., Forlizzi, J., & Hodgins, J. (2006). A storytelling robot: Modeling and evaluation of human-like gaze behavior. ",(0,r.jsx)(e.em,{children:"International Conference on Intelligent Robots and Systems"}),", 5184-5189."]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Gaze behavior modeling"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:["Tapus, A., Mataric, M. J., & Scassellati, B. (2007). The grand challenge of social assistive robotics. ",(0,r.jsx)(e.em,{children:"IEEE Robotics & Automation Magazine"}),", 14(1), 35-36."]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.em,{children:"Social assistive robotics challenge"})}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"online-resources",children:"Online Resources"}),"\n",(0,r.jsx)(e.h3,{id:"official-documentation",children:"Official Documentation"}),"\n",(0,r.jsxs)(e.ol,{start:"101",children:["\n",(0,r.jsxs)(e.li,{children:["ROS 2 Documentation: ",(0,r.jsx)(e.a,{href:"https://docs.ros.org/en/humble/",children:"https://docs.ros.org/en/humble/"})]}),"\n",(0,r.jsxs)(e.li,{children:["NVIDIA Isaac ROS: ",(0,r.jsx)(e.a,{href:"https://nvidia-isaac-ros.github.io/",children:"https://nvidia-isaac-ros.github.io/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Isaac Sim Documentation: ",(0,r.jsx)(e.a,{href:"https://docs.omniverse.nvidia.com/isaacsim/latest/",children:"https://docs.omniverse.nvidia.com/isaacsim/latest/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Gazebo Simulation: ",(0,r.jsx)(e.a,{href:"https://gazebosim.org/",children:"https://gazebosim.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["OpenCV Documentation: ",(0,r.jsx)(e.a,{href:"https://docs.opencv.org/",children:"https://docs.opencv.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["PyTorch Documentation: ",(0,r.jsx)(e.a,{href:"https://pytorch.org/docs/stable/index.html",children:"https://pytorch.org/docs/stable/index.html"})]}),"\n",(0,r.jsxs)(e.li,{children:["Hugging Face Documentation: ",(0,r.jsx)(e.a,{href:"https://huggingface.co/docs",children:"https://huggingface.co/docs"})]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"research-repositories",children:"Research Repositories"}),"\n",(0,r.jsxs)(e.ol,{start:"108",children:["\n",(0,r.jsxs)(e.li,{children:["arXiv Robotics: ",(0,r.jsx)(e.a,{href:"https://arxiv.org/list/cs.RO/recent",children:"https://arxiv.org/list/cs.RO/recent"})]}),"\n",(0,r.jsxs)(e.li,{children:["arXiv AI: ",(0,r.jsx)(e.a,{href:"https://arxiv.org/list/cs.AI/recent",children:"https://arxiv.org/list/cs.AI/recent"})]}),"\n",(0,r.jsxs)(e.li,{children:["arXiv Computer Vision: ",(0,r.jsx)(e.a,{href:"https://arxiv.org/list/cs.CV/recent",children:"https://arxiv.org/list/cs.CV/recent"})]}),"\n",(0,r.jsxs)(e.li,{children:["NVIDIA Research Robotics: ",(0,r.jsx)(e.a,{href:"https://research.nvidia.com/labs/toronto-ai/",children:"https://research.nvidia.com/labs/toronto-ai/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Google AI Robotics: ",(0,r.jsx)(e.a,{href:"https://ai.google/research/teams/brain/robotics",children:"https://ai.google/research/teams/brain/robotics"})]}),"\n",(0,r.jsxs)(e.li,{children:["OpenAI Robotics: ",(0,r.jsx)(e.a,{href:"https://openai.com/research/robotics",children:"https://openai.com/research/robotics"})]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"development-tools",children:"Development Tools"}),"\n",(0,r.jsxs)(e.ol,{start:"114",children:["\n",(0,r.jsxs)(e.li,{children:["GitHub Robotics: ",(0,r.jsx)(e.a,{href:"https://github.com/topics/robotics",children:"https://github.com/topics/robotics"})]}),"\n",(0,r.jsxs)(e.li,{children:["Robot Operating System GitHub: ",(0,r.jsx)(e.a,{href:"https://github.com/ros",children:"https://github.com/ros"})]}),"\n",(0,r.jsxs)(e.li,{children:["NVIDIA Isaac ROS GitHub: ",(0,r.jsx)(e.a,{href:"https://github.com/NVIDIA-ISAAC-ROS",children:"https://github.com/NVIDIA-ISAAC-ROS"})]}),"\n",(0,r.jsxs)(e.li,{children:["ROS Industrial: ",(0,r.jsx)(e.a,{href:"https://ros-industrial.org/",children:"https://ros-industrial.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["PickNik Robotics: ",(0,r.jsx)(e.a,{href:"https://picknik.ai/",children:"https://picknik.ai/"})]}),"\n",(0,r.jsxs)(e.li,{children:["The Construct: ",(0,r.jsx)(e.a,{href:"https://www.theconstructsim.com/",children:"https://www.theconstructsim.com/"})]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"conferences-and-journals",children:"Conferences and Journals"}),"\n",(0,r.jsxs)(e.ol,{start:"120",children:["\n",(0,r.jsxs)(e.li,{children:["IEEE Robotics and Automation Society: ",(0,r.jsx)(e.a,{href:"https://www.ieee-ras.org/",children:"https://www.ieee-ras.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["International Conference on Robotics and Automation (ICRA): ",(0,r.jsx)(e.a,{href:"https://www.icra.cc/",children:"https://www.icra.cc/"})]}),"\n",(0,r.jsxs)(e.li,{children:["International Conference on Intelligent Robots and Systems (IROS): ",(0,r.jsx)(e.a,{href:"https://www.iros.org/",children:"https://www.iros.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Conference on Robot Learning (CoRL): ",(0,r.jsx)(e.a,{href:"https://www.robot-learning.org/",children:"https://www.robot-learning.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["IEEE Transactions on Robotics: ",(0,r.jsx)(e.a,{href:"https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8860",children:"https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=8860"})]}),"\n",(0,r.jsxs)(e.li,{children:["The International Journal of Robotics Research: ",(0,r.jsx)(e.a,{href:"https://journals.sagepub.com/home/ijr",children:"https://journals.sagepub.com/home/ijr"})]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"educational-resources",children:"Educational Resources"}),"\n",(0,r.jsxs)(e.ol,{start:"126",children:["\n",(0,r.jsxs)(e.li,{children:["MIT OpenCourseWare Robotics: ",(0,r.jsx)(e.a,{href:"https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-141-robotics-science-and-systems-i-fall-2019/",children:"https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-141-robotics-science-and-systems-i-fall-2019/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Stanford CS 223A: ",(0,r.jsx)(e.a,{href:"https://cs.stanford.edu/groups/manips/teaching/cs223a/",children:"https://cs.stanford.edu/groups/manips/teaching/cs223a/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Carnegie Mellon Robotics Institute: ",(0,r.jsx)(e.a,{href:"https://www.ri.cmu.edu/",children:"https://www.ri.cmu.edu/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Coursera Robotics Specialization: ",(0,r.jsx)(e.a,{href:"https://www.coursera.org/specializations/robotics",children:"https://www.coursera.org/specializations/robotics"})]}),"\n",(0,r.jsxs)(e.li,{children:["edX Robotics: ",(0,r.jsx)(e.a,{href:"https://www.edx.org/learn/robotics",children:"https://www.edx.org/learn/robotics"})]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"simulation-platforms",children:"Simulation Platforms"}),"\n",(0,r.jsxs)(e.ol,{start:"131",children:["\n",(0,r.jsxs)(e.li,{children:["Isaac Sim Examples: ",(0,r.jsx)(e.a,{href:"https://github.com/NVIDIA-Omniverse/IsaacSim",children:"https://github.com/NVIDIA-Omniverse/IsaacSim"})]}),"\n",(0,r.jsxs)(e.li,{children:["Isaac Lab Examples: ",(0,r.jsx)(e.a,{href:"https://isaac-sim.github.io/IsaacLab/",children:"https://isaac-sim.github.io/IsaacLab/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Gazebo Tutorials: ",(0,r.jsx)(e.a,{href:"https://gazebosim.org/tutorials",children:"https://gazebosim.org/tutorials"})]}),"\n",(0,r.jsxs)(e.li,{children:["Unity Robotics Hub: ",(0,r.jsx)(e.a,{href:"https://github.com/Unity-Technologies/Unity-Robotics-Hub",children:"https://github.com/Unity-Technologies/Unity-Robotics-Hub"})]}),"\n",(0,r.jsxs)(e.li,{children:["Webots Robotics: ",(0,r.jsx)(e.a,{href:"https://cyberbotics.com/doc/guide/index",children:"https://cyberbotics.com/doc/guide/index"})]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"ai-and-machine-learning",children:"AI and Machine Learning"}),"\n",(0,r.jsxs)(e.ol,{start:"136",children:["\n",(0,r.jsxs)(e.li,{children:["Hugging Face Models: ",(0,r.jsx)(e.a,{href:"https://huggingface.co/models",children:"https://huggingface.co/models"})]}),"\n",(0,r.jsxs)(e.li,{children:["NVIDIA AI Enterprise: ",(0,r.jsx)(e.a,{href:"https://www.nvidia.com/en-us/data-center/products/ai-enterprise/",children:"https://www.nvidia.com/en-us/data-center/products/ai-enterprise/"})]}),"\n",(0,r.jsxs)(e.li,{children:["TensorFlow: ",(0,r.jsx)(e.a,{href:"https://www.tensorflow.org/",children:"https://www.tensorflow.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["PyTorch: ",(0,r.jsx)(e.a,{href:"https://pytorch.org/",children:"https://pytorch.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Stable Diffusion: ",(0,r.jsx)(e.a,{href:"https://stability.ai/news/stable-diffusion-public-release",children:"https://stability.ai/news/stable-diffusion-public-release"})]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"community-and-support",children:"Community and Support"}),"\n",(0,r.jsxs)(e.ol,{start:"141",children:["\n",(0,r.jsxs)(e.li,{children:["ROS Discourse: ",(0,r.jsx)(e.a,{href:"https://discourse.ros.org/",children:"https://discourse.ros.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["ROS Answers: ",(0,r.jsx)(e.a,{href:"https://answers.ros.org/questions/",children:"https://answers.ros.org/questions/"})]}),"\n",(0,r.jsxs)(e.li,{children:["NVIDIA Developer Forum: ",(0,r.jsx)(e.a,{href:"https://forums.developer.nvidia.com/",children:"https://forums.developer.nvidia.com/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Reddit r/Robotics: ",(0,r.jsx)(e.a,{href:"https://www.reddit.com/r/robotics/",children:"https://www.reddit.com/r/robotics/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Reddit r/ROS: ",(0,r.jsx)(e.a,{href:"https://www.reddit.com/r/ros/",children:"https://www.reddit.com/r/ros/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Robohub: ",(0,r.jsx)(e.a,{href:"https://robohub.org/",children:"https://robohub.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["The Robot Report: ",(0,r.jsx)(e.a,{href:"https://www.therobotreport.com/",children:"https://www.therobotreport.com/"})]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"industry-applications",children:"Industry Applications"}),"\n",(0,r.jsxs)(e.ol,{start:"148",children:["\n",(0,r.jsxs)(e.li,{children:["Boston Dynamics: ",(0,r.jsx)(e.a,{href:"https://www.bostondynamics.com/",children:"https://www.bostondynamics.com/"})]}),"\n",(0,r.jsxs)(e.li,{children:["ABB Robotics: ",(0,r.jsx)(e.a,{href:"https://new.abb.com/products/robotics",children:"https://new.abb.com/products/robotics"})]}),"\n",(0,r.jsxs)(e.li,{children:["KUKA Robotics: ",(0,r.jsx)(e.a,{href:"https://www.kuka.com/en-us",children:"https://www.kuka.com/en-us"})]}),"\n",(0,r.jsxs)(e.li,{children:["Universal Robots: ",(0,r.jsx)(e.a,{href:"https://www.universal-robots.com/",children:"https://www.universal-robots.com/"})]}),"\n",(0,r.jsxs)(e.li,{children:["SoftBank Robotics: ",(0,r.jsx)(e.a,{href:"https://www.softbankrobotics.com/",children:"https://www.softbankrobotics.com/"})]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"hardware-and-sensors",children:"Hardware and Sensors"}),"\n",(0,r.jsxs)(e.ol,{start:"153",children:["\n",(0,r.jsxs)(e.li,{children:["Intel RealSense: ",(0,r.jsx)(e.a,{href:"https://www.intelrealsense.com/",children:"https://www.intelrealsense.com/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Velodyne LiDAR: ",(0,r.jsx)(e.a,{href:"https://velodynelidar.com/",children:"https://velodynelidar.com/"})]}),"\n",(0,r.jsxs)(e.li,{children:["NVIDIA Jetson: ",(0,r.jsx)(e.a,{href:"https://developer.nvidia.com/embedded/jetson-developer-kits",children:"https://developer.nvidia.com/embedded/jetson-developer-kits"})]}),"\n",(0,r.jsxs)(e.li,{children:["Dynamixel Servos: ",(0,r.jsx)(e.a,{href:"https://emanual.robotis.com/",children:"https://emanual.robotis.com/"})]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"datasets-and-benchmarks",children:"Datasets and Benchmarks"}),"\n",(0,r.jsxs)(e.ol,{start:"157",children:["\n",(0,r.jsxs)(e.li,{children:["Robot Data Sets: ",(0,r.jsx)(e.a,{href:"https://robotics-data-set.cs.utah.edu/",children:"https://robotics-data-set.cs.utah.edu/"})]}),"\n",(0,r.jsxs)(e.li,{children:["KITTI Vision Benchmark: ",(0,r.jsx)(e.a,{href:"http://www.cvlibs.net/datasets/kitti/",children:"http://www.cvlibs.net/datasets/kitti/"})]}),"\n",(0,r.jsxs)(e.li,{children:["COCO Dataset: ",(0,r.jsx)(e.a,{href:"https://cocodataset.org/",children:"https://cocodataset.org/"})]}),"\n",(0,r.jsxs)(e.li,{children:["YCB Object and Model Set: ",(0,r.jsx)(e.a,{href:"https://ycb-benchmarks.s3-us-west-2.amazonaws.com/",children:"https://ycb-benchmarks.s3-us-west-2.amazonaws.com/"})]}),"\n",(0,r.jsxs)(e.li,{children:["Open Images Dataset: ",(0,r.jsx)(e.a,{href:"https://storage.googleapis.com/openimages/web/index.html",children:"https://storage.googleapis.com/openimages/web/index.html"})]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"tutorials-and-courses",children:"Tutorials and Courses"}),"\n",(0,r.jsxs)(e.ol,{start:"162",children:["\n",(0,r.jsxs)(e.li,{children:["ROS 2 Tutorials: ",(0,r.jsx)(e.a,{href:"https://docs.ros.org/en/humble/Tutorials.html",children:"https://docs.ros.org/en/humble/Tutorials.html"})]}),"\n",(0,r.jsxs)(e.li,{children:["Isaac ROS Tutorials: ",(0,r.jsx)(e.a,{href:"https://nvidia-isaac-ros.github.io/repositories_and_packages/isaac_ros_examples/index.html",children:"https://nvidia-isaac-ros.github.io/repositories_and_packages/isaac_ros_examples/index.html"})]}),"\n",(0,r.jsxs)(e.li,{children:["Navigation2 Tutorials: ",(0,r.jsx)(e.a,{href:"https://navigation.ros.org/tutorials/index.html",children:"https://navigation.ros.org/tutorials/index.html"})]}),"\n",(0,r.jsxs)(e.li,{children:["OpenCV Tutorials: ",(0,r.jsx)(e.a,{href:"https://docs.opencv.org/4.x/d9/df8/tutorial_root.html",children:"https://docs.opencv.org/4.x/d9/df8/tutorial_root.html"})]}),"\n",(0,r.jsxs)(e.li,{children:["PyTorch Tutorials: ",(0,r.jsx)(e.a,{href:"https://pytorch.org/tutorials/",children:"https://pytorch.org/tutorials/"})]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.p,{children:"This bibliography provides a comprehensive collection of academic papers, technical documentation, online resources, and educational materials relevant to Physical AI and robotics development. The references span foundational research, current state-of-the-art approaches, and practical implementation resources that support the curriculum covered in this book."})]})}function h(n={}){const{wrapper:e}={...(0,l.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>a});var s=i(6540);const r={},l=s.createContext(r);function o(n){const e=s.useContext(l);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:o(n.components),s.createElement(l.Provider,{value:e},n.children)}}}]);