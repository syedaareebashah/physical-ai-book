"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[5424],{8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>l});var r=s(6540);const i={},a=r.createContext(i);function t(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),r.createElement(a.Provider,{value:n},e.children)}},9222:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>p,frontMatter:()=>t,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"module1-ros2/python-rclpy","title":"Python Integration with rclpy","description":"Chapter Objectives","source":"@site/docs/module1-ros2/04-python-rclpy.md","sourceDirName":"module1-ros2","slug":"/module1-ros2/python-rclpy","permalink":"/physical-ai-book/docs/module1-ros2/python-rclpy","draft":false,"unlisted":false,"editUrl":"https://github.com/syedaareebashah/physical-ai-book/edit/main/docs/module1-ros2/04-python-rclpy.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"tutorialSidebar","previous":{"title":"Your First ROS 2 Node","permalink":"/physical-ai-book/docs/module1-ros2/first-node"},"next":{"title":"URDF for Humanoid Robots","permalink":"/physical-ai-book/docs/module1-ros2/urdf"}}');var i=s(4848),a=s(8453);const t={sidebar_position:4},l="Python Integration with rclpy",o={},c=[{value:"Chapter Objectives",id:"chapter-objectives",level:2},{value:"Understanding rclpy",id:"understanding-rclpy",level:2},{value:"Core rclpy Concepts",id:"core-rclpy-concepts",level:3},{value:"Advanced Node Features",id:"advanced-node-features",level:2},{value:"Parameters",id:"parameters",level:3},{value:"Actions",id:"actions",level:3},{value:"Asynchronous Programming with rclpy",id:"asynchronous-programming-with-rclpy",level:2},{value:"Async Nodes",id:"async-nodes",level:3},{value:"Async Service Implementation",id:"async-service-implementation",level:3},{value:"Physical AI Integration with Python Libraries",id:"physical-ai-integration-with-python-libraries",level:2},{value:"Computer Vision Integration",id:"computer-vision-integration",level:3},{value:"Machine Learning Integration",id:"machine-learning-integration",level:3},{value:"Best Practices for Physical AI Applications",id:"best-practices-for-physical-ai-applications",level:2},{value:"Error Handling and Safety",id:"error-handling-and-safety",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Chapter Summary",id:"chapter-summary",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"python-integration-with-rclpy",children:"Python Integration with rclpy"})}),"\n",(0,i.jsx)(n.h2,{id:"chapter-objectives",children:"Chapter Objectives"}),"\n",(0,i.jsx)(n.p,{children:"By the end of this chapter, you will be able to:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Use rclpy to create sophisticated ROS 2 nodes in Python"}),"\n",(0,i.jsx)(n.li,{children:"Implement advanced communication patterns (actions, parameters)"}),"\n",(0,i.jsx)(n.li,{children:"Handle asynchronous operations and callbacks"}),"\n",(0,i.jsx)(n.li,{children:"Design robust Physical AI applications in Python"}),"\n",(0,i.jsx)(n.li,{children:"Integrate with Python's rich ecosystem of AI libraries"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"understanding-rclpy",children:"Understanding rclpy"}),"\n",(0,i.jsx)(n.p,{children:"rclpy is the Python client library for ROS 2, providing Python bindings for the ROS 2 client library (rcl). It allows Python developers to leverage ROS 2's capabilities while using Python's extensive libraries for AI, machine learning, and robotics."}),"\n",(0,i.jsx)(n.h3,{id:"core-rclpy-concepts",children:"Core rclpy Concepts"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\n\nclass AdvancedNode(Node):\n    def __init__(self):\n        super().__init__('advanced_node')\n\n        # Node initialization with parameters\n        self.declare_parameter('sensor_frequency', 10.0)\n        self.frequency = self.get_parameter('sensor_frequency').value\n\n        # Logging\n        self.get_logger().info(f'Node initialized with frequency: {self.frequency}Hz')\n"})}),"\n",(0,i.jsx)(n.h2,{id:"advanced-node-features",children:"Advanced Node Features"}),"\n",(0,i.jsx)(n.h3,{id:"parameters",children:"Parameters"}),"\n",(0,i.jsx)(n.p,{children:"Parameters allow runtime configuration of nodes:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom rclpy.parameter import Parameter\nfrom rcl_interfaces.msg import ParameterDescriptor\n\nclass ParameterNode(Node):\n    def __init__(self):\n        super().__init__('parameter_node')\n\n        # Declare parameters with descriptions\n        self.declare_parameter(\n            'max_velocity',\n            1.0,\n            ParameterDescriptor(description='Maximum robot velocity in m/s')\n        )\n\n        self.declare_parameter('robot_name', 'my_robot')\n\n        # Set parameter callback\n        self.add_on_set_parameters_callback(self.parameter_callback)\n\n        # Create timer that uses parameters\n        self.timer = self.create_timer(0.1, self.timer_callback)\n\n    def parameter_callback(self, params):\n        for param in params:\n            if param.name == 'max_velocity' and param.value > 5.0:\n                return SetParametersResult(successful=False, reason='Velocity too high')\n        return SetParametersResult(successful=True)\n\n    def timer_callback(self):\n        max_vel = self.get_parameter('max_velocity').value\n        robot_name = self.get_parameter('robot_name').value\n        self.get_logger().info(f'{robot_name} max velocity: {max_vel} m/s')\n"})}),"\n",(0,i.jsx)(n.h3,{id:"actions",children:"Actions"}),"\n",(0,i.jsx)(n.p,{children:"Actions provide goal-oriented communication for long-running tasks:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.action import ActionServer, CancelResponse, GoalResponse\nfrom rclpy.node import Node\nfrom example_interfaces.action import Fibonacci\n\nclass FibonacciActionServer(Node):\n    def __init__(self):\n        super().__init__('fibonacci_action_server')\n        self._action_server = ActionServer(\n            self,\n            Fibonacci,\n            'fibonacci',\n            execute_callback=self.execute_callback,\n            goal_callback=self.goal_callback,\n            cancel_callback=self.cancel_callback)\n\n    def goal_callback(self, goal_request):\n        self.get_logger().info('Received goal request')\n        return GoalResponse.ACCEPT\n\n    def cancel_callback(self, goal_handle):\n        self.get_logger().info('Received cancel request')\n        return CancelResponse.ACCEPT\n\n    async def execute_callback(self, goal_handle):\n        self.get_logger().info('Executing goal...')\n\n        feedback_msg = Fibonacci.Feedback()\n        feedback_msg.sequence = [0, 1]\n\n        for i in range(1, goal_handle.request.order):\n            if goal_handle.is_cancel_requested:\n                goal_handle.canceled()\n                self.get_logger().info('Goal canceled')\n                return Fibonacci.Result()\n\n            feedback_msg.sequence.append(\n                feedback_msg.sequence[i] + feedback_msg.sequence[i-1])\n\n            goal_handle.publish_feedback(feedback_msg)\n            self.get_logger().info(f'Feedback: {feedback_msg.sequence}')\n\n        goal_handle.succeed()\n        result = Fibonacci.Result()\n        result.sequence = feedback_msg.sequence\n        self.get_logger().info(f'Result: {result.sequence}')\n\n        return result\n"})}),"\n",(0,i.jsx)(n.h2,{id:"asynchronous-programming-with-rclpy",children:"Asynchronous Programming with rclpy"}),"\n",(0,i.jsx)(n.h3,{id:"async-nodes",children:"Async Nodes"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nimport asyncio\n\nclass AsyncNode(Node):\n    def __init__(self):\n        super().__init__('async_node')\n\n        # Create async timer\n        self.async_timer = self.create_timer(\n            1.0,\n            self.async_timer_callback\n        )\n\n    def async_timer_callback(self):\n        # Schedule async task\n        self.executor.create_task(self.background_task())\n\n    async def background_task(self):\n        # Simulate async work\n        await asyncio.sleep(0.5)\n        self.get_logger().info('Async task completed')\n"})}),"\n",(0,i.jsx)(n.h3,{id:"async-service-implementation",children:"Async Service Implementation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom example_interfaces.srv import AddTwoInts\nimport asyncio\n\nclass AsyncServiceNode(Node):\n    def __init__(self):\n        super().__init__('async_service')\n        self.srv = self.create_service(\n            AddTwoInts,\n            'async_add_two_ints',\n            self.handle_async_request\n        )\n\n    async def handle_async_request(self, request, response):\n        # Simulate async processing\n        await asyncio.sleep(0.1)\n        response.sum = request.a + request.b\n        return response\n"})}),"\n",(0,i.jsx)(n.h2,{id:"physical-ai-integration-with-python-libraries",children:"Physical AI Integration with Python Libraries"}),"\n",(0,i.jsx)(n.h3,{id:"computer-vision-integration",children:"Computer Vision Integration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge\nimport cv2\nimport numpy as np\n\nclass VisionNode(Node):\n    def __init__(self):\n        super().__init__('vision_node')\n        self.subscription = self.create_subscription(\n            Image,\n            'camera/image_raw',\n            self.image_callback,\n            10)\n\n        self.publisher = self.create_publisher(Image, 'camera/image_processed', 10)\n        self.bridge = CvBridge()\n\n    def image_callback(self, msg):\n        try:\n            # Convert ROS Image message to OpenCV image\n            cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\n\n            # Apply computer vision processing\n            processed_image = self.process_image(cv_image)\n\n            # Convert back to ROS Image message\n            processed_msg = self.bridge.cv2_to_imgmsg(processed_image, \"bgr8\")\n            processed_msg.header = msg.header\n\n            self.publisher.publish(processed_msg)\n\n        except Exception as e:\n            self.get_logger().error(f'Error processing image: {e}')\n\n    def process_image(self, image):\n        # Apply edge detection\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        edges = cv2.Canny(gray, 50, 150)\n\n        # Combine with original\n        result = image.copy()\n        result[edges != 0] = [0, 255, 0]  # Highlight edges in green\n\n        return result\n"})}),"\n",(0,i.jsx)(n.h3,{id:"machine-learning-integration",children:"Machine Learning Integration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import LaserScan\nfrom std_msgs.msg import String\nfrom sklearn.cluster import DBSCAN\nimport numpy as np\n\nclass MLProcessingNode(Node):\n    def __init__(self):\n        super().__init__('ml_processing_node')\n        self.subscription = self.create_subscription(\n            LaserScan,\n            'laser_scan',\n            self.scan_callback,\n            10)\n\n        self.publisher = self.create_publisher(String, 'object_detection', 10)\n\n    def scan_callback(self, msg):\n        # Convert laser scan to points\n        points = self.laser_scan_to_points(msg)\n\n        if len(points) > 0:\n            # Apply clustering to detect objects\n            clusters = self.detect_objects(points)\n\n            # Publish results\n            result_msg = String()\n            result_msg.data = f'Detected {len(clusters)} objects'\n            self.publisher.publish(result_msg)\n\n    def laser_scan_to_points(self, scan):\n        points = []\n        angle = scan.angle_min\n\n        for range_val in scan.ranges:\n            if scan.range_min <= range_val <= scan.range_max:\n                x = range_val * np.cos(angle)\n                y = range_val * np.sin(angle)\n                points.append([x, y])\n            angle += scan.angle_increment\n\n        return np.array(points)\n\n    def detect_objects(self, points):\n        if len(points) < 2:\n            return []\n\n        # Apply DBSCAN clustering\n        clustering = DBSCAN(eps=0.5, min_samples=3).fit(points)\n        labels = clustering.labels_\n\n        # Group points by cluster\n        clusters = {}\n        for i, label in enumerate(labels):\n            if label not in clusters:\n                clusters[label] = []\n            clusters[label].append(points[i])\n\n        # Filter out noise (label -1)\n        return {k: v for k, v in clusters.items() if k != -1}\n"})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices-for-physical-ai-applications",children:"Best Practices for Physical AI Applications"}),"\n",(0,i.jsx)(n.h3,{id:"error-handling-and-safety",children:"Error Handling and Safety"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile, ReliabilityPolicy\nimport traceback\n\nclass SafeNode(Node):\n    def __init__(self):\n        super().__init__('safe_node')\n\n        # Use appropriate QoS for safety-critical topics\n        qos_profile = QoSProfile(\n            depth=1,\n            reliability=ReliabilityPolicy.RELIABLE\n        )\n\n        self.subscription = self.create_subscription(\n            String, 'critical_topic', self.safe_callback, qos_profile\n        )\n\n    def safe_callback(self, msg):\n        try:\n            # Process message\n            result = self.process_message(msg)\n            # Validate result\n            if self.validate_result(result):\n                self.publish_result(result)\n            else:\n                self.get_logger().error('Invalid result detected')\n        except Exception as e:\n            self.get_logger().error(f'Error in callback: {e}')\n            traceback.print_exc()\n            # Implement safety measures\n            self.emergency_stop()\n\n    def validate_result(self, result):\n        # Add validation logic\n        return True\n\n    def emergency_stop(self):\n        # Implement emergency procedures\n        self.get_logger().warn('Emergency stop activated')\n"})}),"\n",(0,i.jsx)(n.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nimport threading\nfrom queue import Queue\n\nclass OptimizedNode(Node):\n    def __init__(self):\n        super().__init__('optimized_node')\n\n        # Use threading for CPU-intensive tasks\n        self.processing_queue = Queue(maxsize=5)\n        self.result_queue = Queue()\n\n        self.subscription = self.create_subscription(\n            Image, 'camera/image_raw', self.image_callback, 10\n        )\n\n        # Start processing thread\n        self.processing_thread = threading.Thread(target=self.process_images)\n        self.processing_thread.daemon = True\n        self.processing_thread.start()\n\n    def image_callback(self, msg):\n        # Add to processing queue if not full\n        if not self.processing_queue.full():\n            self.processing_queue.put(msg)\n\n    def process_images(self):\n        while rclpy.ok():\n            try:\n                msg = self.processing_queue.get(timeout=0.1)\n                # Process image in separate thread\n                result = self.heavy_computation(msg)\n                self.result_queue.put(result)\n            except:\n                continue  # Timeout is normal\n\n    def heavy_computation(self, msg):\n        # Perform heavy computation\n        pass\n"})}),"\n",(0,i.jsx)(n.h2,{id:"chapter-summary",children:"Chapter Summary"}),"\n",(0,i.jsx)(n.p,{children:"Python integration with rclpy enables powerful Physical AI applications by combining ROS 2's distributed computing capabilities with Python's rich ecosystem of AI and machine learning libraries. Advanced features like parameters, actions, and asynchronous programming provide the flexibility needed for complex robotic systems."}),"\n",(0,i.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Create a node that uses TensorFlow or PyTorch for real-time object detection from camera feeds."}),"\n",(0,i.jsx)(n.li,{children:"Implement an action server that performs path planning with feedback."}),"\n",(0,i.jsx)(n.li,{children:"Design a parameter server that allows runtime configuration of robot behaviors."}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsx)(n.p,{children:"In the next chapter, we'll explore URDF (Unified Robot Description Format) for describing humanoid robots in Physical AI systems."})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);